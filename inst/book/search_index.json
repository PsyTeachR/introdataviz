[["index.html", "Data visualisation using R, for researchers who don’t use R Overview", " Data visualisation using R, for researchers who don’t use R Emily Nordmann, Phil McAleer, Wilhelmiina Toivo, Helena Paterson, Lisa DeBruine 2021-06-21 Overview This is a pre-submission manuscript and tutorial and has not yet undergone peer-review. We welcome user feedback which you can provide using this form. Please note that this tutorial is likely to undergo changes before it is accepted for publication and we would encourage you to check for updates before citing. Please cite this tutorial as: Nordmann, E., McAleer, P., Toivo, W., Paterson, H. &amp; DeBruine, L. (2021). Data visualisation using R, for researchers who don’t use R. Preprint. DOI WHEN GENERATED "],["introduction.html", "Chapter 1 Introduction 1.1 Why R for data visualisation? 1.2 A layered grammar of graphics 1.3 Simulated dataset 1.4 Setting up R and RStudio 1.5 Preparing your data", " Chapter 1 Introduction Use of the programming language R (R Core Team 2021) for data processing and statistical analysis by researchers is increasingly common, with an average yearly growth of 87% in the number of citations of the R Core Team between 2006-2018 (Barrett 2019). In addition to benefiting reproducibility and transparency, one of the advantages of using R is that researchers have a much larger range of fully customisable data visualisations options than are typically available in point-and-click software, due to the open-source nature of R. These visualisation options not only look attractive, but can increase transparency about the distribution of the underlying data rather than relying on commonly used visualisations of aggregations such as bar charts of means (Newman and Scholl 2012). Yet, the benefits of using R are obscured for many researchers by the perception that coding skills are difficult to learn (Robins, Rountree, and Rountree 2003). Coupled with this, only a minority of psychology programmes currently teach coding skills (Wills, n.d.) with the majority of both undergraduate and postgraduate courses using proprietary point-and-click software such as SAS, SPSS or Microsoft Excel. While the sophisticated use of proprietary software often necessitates the use of computational thinking skills akin to coding (for instance SPSS scripts or formulas in Excel), we have found that many researchers do not perceive that they already have introductory coding skills. In the following tutorial we intend to change that perception by showing how experienced researchers can redevelop their existing computational skills to utilise the powerful data visualisation tools offered by R. In this tutorial, we aim to provide a practical introduction to data visualisation using R, specifically aimed at researchers who have little to no prior experience of using R. First we detail the rationale for using R for data visualisation and introduce the “grammar of graphics” that underlies data visualisation using the ggplot package. The tutorial then walks the reader through how to replicate plots that are commonly available in point-and-click software such as histograms and boxplots, as well as showing how the code for these “basic” plots can be easily extended to less commonly available options such as violin-boxplots. 1.1 Why R for data visualisation? Data visualisation benefits from the same advantages as statistical analysis when writing code rather than using point-and-click software – reproducibility and transparency. The need for psychological researchers to work in reproducible ways has been well-documented and discussed in response to the replication crisis (e.g. Munafò et al. 2017) and we will not repeat those arguments here. However, there is an additional benefit to reproducibility that is less frequently acknowledged compared to the loftier goals of improving psychological science: if you write code to produce your plots, you can reuse and adapt that code in the future rather than starting from scratch each time. In addition to the benefits of reproducibility, using R for data visualisation gives the researcher almost total control over each element of the plot. Whilst this flexibility can seem daunting at first, the ability to write reusable code recipes (and use recipes created by others) is highly advantageous. The level of customisation and the professional outputs available using R has, for instance, lead news outlets such as the BBC (Visual and Journalism 2019) and the New York Times (Bertini and Stefaner 2015) to adopt R as their preferred data visualisation tool. 1.2 A layered grammar of graphics There are multiple approaches to data visualisation in R; in this paper we use the popular package1 ggplot2 (Wickham 2016) which is part of the larger tidyverse2 (Wickham 2017) collection of packages that provide functions for data wrangling, descriptives, and visualisation. A grammar of graphics (Wilkinson, Anand, and Grossman 2005) is a standardised way to describe the components of a graphic. ggplot2 uses a layered grammar of graphics (Wickham 2010), in which plots are built up in a series of layers. It may be helpful to think about any picture as having multiple elements that sit semi-transparently over each other. A good analogy is old Disney movies where artists would create a background and then add moveable elements on top of the background via transparencies. Figure 1.1 displays the evolution of a simple scatterplot using this layered approach. First, the plot space is built (layer 1); the variables are specified (layer 2); the type of visualisation (known as a geom) that is desired for these variables is specified (layer 3) - in this case geom_point() is called to visualise individual data points; a second geom is added to include a line of best fit (layer 4), the axis labels are edited for readability (layer 5), and finally, a theme is applied to change the overall appearance of the plot (layer 6). a &lt;- ggplot() + labs(subtitle = &quot;Layer 1&quot;) b &lt;- ggplot(iris, aes(Sepal.Length, Sepal.Width)) + labs(subtitle = &quot;Layer 2&quot;) c &lt;- b + geom_point() + labs(subtitle = &quot;Layer 3&quot;) d &lt;- c + geom_smooth(method = &quot;lm&quot;) + labs(subtitle = &quot;Layer 4&quot;) e &lt;- d + labs(x = &quot;Sepal Length (mm)&quot;, y = &quot;Sepal Width (mm)&quot;) + labs(subtitle = &quot;Layer 5&quot;) f &lt;- e + theme_minimal(base_family = &quot;Times&quot;) + labs(subtitle = &quot;Layer 6&quot;) a + b + c + d + e + f + plot_layout(nrow = 2) Figure 1.1: Evolution of a layered plot Importantly, each layer is independent and independently customisable. For example, the size, colour and position of each component can be adjusted, or one could, for example, remove the first geom (the data points) to only visualise the line of best fit, simply by removing the layer that draws the data points (Figure 1.2). The use of layers makes it easy to build up complex plots step-by-step, and to adapt or extend plots from existing code. iris %&gt;% ggplot(aes(Sepal.Length, Sepal.Width)) + geom_smooth(method = &quot;lm&quot;) + labs(x = &quot;Sepal Length (mm)&quot;, y = &quot;Sepal Width (mm)&quot;)+ theme_minimal() Figure 1.2: Plot with scatterplot layer removed. 1.3 Simulated dataset For the purpose of this tutorial, we will use simulated data for a 2 x 2 mixed-design lexical decision task in which participants have to decide whether a presented word is a real word, or a non-word, with 100 participants. There are 100 rows (1 for each participant) and 7 variables: Participant information: id: Participant ID age: Age 1 between-subject IV: language: Language group (1 = monolingual, 2 = bilingual) 4 columns for the 2 dependent variables for RT and accuracy, crossed by the within-subject IV of condition: rt_word: Reaction time (ms) for word trials rt_nonword: Reaction time (ms) for non-word trials acc_word: Accuracy for word trials acc_nonword: Accuracy for non-word trials The simulated dataset and tutorial code can be found in the online supplementary materials. For newcomers to R, we would suggest working through this tutorial with the simulated dataset, then extending the code to your own datasets with a similar structure, and finally generalising the code to new structures and problems. 1.4 Setting up R and RStudio We strongly encourage the use of RStudio (RStudio Team 2021) to write code in R. R is the programming language whilst RStudio is an integrated development environment that makes working with R easier. More information on installing both R and RStudio can be found in the additional resources. Projects are a useful way of keeping all your code, data, and output in one place. To create a new project, open RStudio and click File - New Project - New Directory - New Project. You will be prompted to give the project a name, and select a location for where to store the project on your computer. Once you have done this, click Create Project. Download the simulated dataset and code tutorial Rmd file from the online materials and then (ldt_data.csv, workbook.Rmd) to this folder. The files pane on the bottom right of RStudio should now display this folder and the files it contains - this is known as your working directory and it is where R will look for any data you wish to import and where it will save any output you create. This tutorial will require you to use the packages contained with the tidyverse collection. Additionally, we will also require use of patchwork. To install these packages, copy and paste the below code into the console (the left hand pane) and press enter to execute the code. # only run in the console, never put this in a script package_list &lt;- c(&quot;tidyverse&quot;, &quot;patchwork&quot;) install.packages(package_list) The R Markdown workbook available in the online materials contains all the code in this tutorial and there is more information and links to additional resources for how to use R Markdown for reproducible reports in the additional resources. The reason that the above install packages code is not included in the workbook is that every time you run the install command code it will install the latest version of the package. Leaving this code in your script can lead you to unintentionally install a package update you didn’t want. For this reason, avoid including install code in any script or Markdown document. 1.5 Preparing your data Before you start visualising your data, you need to get it into an appropriate format. These preparatory steps can all be dealt with reproducibly using R and the additional resources section points to extra tutorials for doing so. However, performing these types of tasks in R can require more sophisticated coding skills and the solutions and tools are dependent on the idiosyncrasies of each dataset. For this reason, in this tutorial we encourage the reader to complete data preparation steps using the method they are most comfortable with and to focus on the aim of data visualisation. 1.5.1 Data format The simulated lexical decision data is provided in a csv file rather than e.g., xslx. Functions exist in R to read many other types of data files, however, we recommend that you convert any xlsx spreadsheets to csv by using the Save As function in Microsoft Excel. The csv file format strips all formatting and only stores data in a single sheet and so is simpler for new users to import to R. You may wish to create a csv file that contains only the data you want to visualise, rather than a full, larger workbook. When working with your own data, remove summary rows or additional notes from any files you import. All files should only contains the rows and columns of data you want to plot. 1.5.2 Variable names Ensuring that your variable names are consistent can make it much easier to work in R. We recommend using short but informative variable names, for example rt_word is preferred over dv1_iv1 or reaction_time_word_condition because these are either hard to read or hard to type. It is also helpful to have a consistent naming scheme, particularly for variable names that require more than one word. Two popular options are CamelCase where each new word begins with a capital letter, or snake_case where all letters are lower case and words are separated by an underscore. For the purposes of naming variables, avoid using any spaces in variable names (e.g., rt word) and consider the additional meaning of a separator beyond making the variable names easier to read. For example, rt_word, rt_nonword, acc_word, and acc_nonword all have the DV to the left of the separator and the level of the IV to the right. rt_word_condition on the other hand has two separators but only one of them is meaningful and it is useful to be able to split variable names consistently. In this paper, we will use snake_case and lower case letters for all variable names so that we don’t have to remember where to put the capital letters. When working with your own data, you can rename columns in Excel, but the resources listed in the additional resources point to how to rename columns reproducibly with code. 1.5.3 Data values A great benefit to using R is that categorical data can be entered as text. In the tutorial dataset, language group is entered as 1 or 2, so that we can show you how to recode numeric values into factors with labels. However, we recommend recording meaningful labels rather than numbers from the beginning of data collection to avoid misinterpreting data due to coding errors. Note that values must match exactly in order to be considered in the same category and R is case sensitive, so “mono,” “Mono,” and “monolingual” would be classified as members of three separate categories. Finally, cells that represent missing data should be left empty rather than containing values like NA, missing or 9993. A complementary rule of thumb is that each column should only contain one type of data, such as words or numbers, not both. References "],["getting-started.html", "Chapter 2 Getting Started 2.1 Loading packages 2.2 Loading data 2.3 Handling numeric factors 2.4 Argument names 2.5 Demographic information 2.6 Bar chart of counts 2.7 Plotting existing aggregates and percent 2.8 Histogram 2.9 Customisation 1 2.10 Activities 1", " Chapter 2 Getting Started 2.1 Loading packages To load the packages that have the functions we need, use the library() function. Whilst you only need to install packages once, you need to load any packages you want to use with library() every time you start R or start a new session. When you load the tidyverse, you actually load several separate packages that are all part of the same collection and have been designed to work well together. R will produce a message that tells you the names of all the packages that have been loaded. library(tidyverse) library(patchwork) 2.2 Loading data To load the simulated sata we use the function read_csv() from the readr tidyverse package. Note that there are many other ways of reading data into R, but the benefit of this function is that it enters the data into the R environment in such a way that it makes most sense for other tidyverse packages. dat &lt;- read_csv(file = &quot;ldt_data.csv&quot;) This code has created an object dat into which you have read the data from the file ldt_data.csv. This object will appear in the environment pane in the top right. Note that the name of the data file must be in quotation marks and the file extension (.csv) must also be included. If you receive the error …does not exist in current working directory it is highly likely that you have made a typo in the file name (remember R is case sensitive), have forgotten to include the file extension .csv, or that the data file you want to load is not stored in your project folder. If you get the error could not find function it means you have either not loaded the correct package (a common beginner error is to write the code, but not run it), or you have made a typo in the function name. To view the dataset, click dat in the environment pane or run View(dat) in the console. The environment pane also tells us that the object dat has 100 observations of 7 variables, and this is a useful quick check to ensure one has loaded the right data. Note that the 7 variables have an additional piece of information chr and num; this specifies the kind of data in the column. Similar to Excel and SPSS, R used this information (or variable type) to specify allowable manipulations of data. For instance character data such as the id cannot be averaged, while it is possible to do this with numerical data such as the age. 2.3 Handling numeric factors Another useful check is to use the functions summary() and str() (structure) to check what kind of data R thinks is in each column. Run the below code and look at the output of each, comparing it with what you know about the simulated dataset: summary(dat) str(dat) Because the factor language is coded as 1 and 2, R has categorised this column as containing numeric information and unless we correct it, this will cause problems for visualisation and analysis. The code below shows how to recode numeric codes into labels. mutate() makes new columns in a data table, or overwrites a column; factor() translates the language column into a factor with the labels “monolingual” and “bilingual.” You can also use factor() to set the display order of a column that contains words. Otherwise, they will display in alphabetical order. In this case we are replacing the numeric data (1 and 2) in the language column with the equivalent English labels monolingual for 1 and bilingual for 2. At the same time we will change the column type to be a factor, which is how R defines categorical data. dat &lt;- dat %&gt;% mutate(language = factor( x = language, # column to translate levels = c(1, 2), # values of the original data in preferred order labels = c(&quot;monolingual&quot;, &quot;bilingual&quot;) # labels for display )) Make sure that you always check the output of any code that you run. If after running this code language is full of NA values, it means that you have run the code twice. The first time would have worked and transformed the values from 1 to monolingual and 2 to bilingual. If you run the code again on the same dataset, it will look for the values 1 and 2, and because there are no longer any that match, it will return NA. If this happens, you will need to reload the dataset from the csv file. A good way to avoid this is never to overwrite data, but to always store the output of code in new objects (e.g., dat_recoded) or new variables (language_recoded). For the purposes of this tutorial, overwriting provides a useful teachable moment so we’ll leave it as it is. 2.4 Argument names Each function has a list of arguments it can take, and a default order for those arguments. You can get more information on each function by entering ?function_name into the console, although be aware that learning to read the help documentation in R is a skill in itself. When you are writing R code, as long as you stick to the default order, you do not have to explicitly call the argument names, for example, the above code could also be written as: dat &lt;- dat %&gt;% mutate(language = factor(language, c(1, 2), c(&quot;monolingual&quot;, &quot;bilingual&quot;))) One of the challenges in learning R is that many of the “helpful” examples and solutions you will find online do not include argument names and so for novice learners are completely opaque. In this tutorial, we will include the argument names the first time a function is used, however, we will remove some argument names from subsequent examples to facilitate knowledge transfer to the help available online. 2.5 Demographic information You can calculate and plot some basic descriptive information about the demographics of our sample using the imported dataset without any additional wrangling (or data processing). The code below uses the %&gt;% operator, otherwise known as the pipe, and can be translated as \"and then\". For example, the below code can be read as: Start with the dataset dat and then; Group it by the variable language and then; Count the number of observations in each group dat %&gt;% group_by(language) %&gt;% count() language n monolingual 55 bilingual 45 group_by() does not result in surface level changes to the dataset, rather, it changes the underlying structure so that if groups are specified, whatever function is called next is performed separately on each level of the grouping variable. The above code therefore counts the number of observations in each group of the variable language. If you just need the total number of observations, you could remove the group_by() line which would perform the operation on the whole dataset, rather than by groups: dat %&gt;% count() n 100 Similarly, we may wish to calculate the mean age (and SD) of the sample and we can do so using the function summarise() from the dplyr tidyverse package. dat %&gt;% summarise(mean_age = mean(age), sd_age = sd(age), n_values = n()) mean_age sd_age n_values 29.75 8.28 100 This code produces summary data in the form of a column named mean_age that contains the result of calculating the mean of the variable age. It then creates sd_age which does the same but for standard deviation. Finally, it uses the function n() to add the number of values used to calculate the statistic in a column named n_values - this is a useful sanity check whenever you make summary statistics. Note that the above code will not save the result of this operation, it will simply output the result in the console. If you wish to save it for future use, you can store it in an object by using the &lt;- notation and print it later by typing the object name. age_stats &lt;- dat %&gt;% summarise(mean_age = mean(age), sd_age = sd(age), n_values = n()) Finally, the group_by() function will work in the same way when calculating summary statistics - the output of the function that is called after group_by() will be produced for each level of the grouping variable. dat %&gt;% group_by(language) %&gt;% summarise(mean_age = mean(age), sd_age = sd(age), n_values = n()) language mean_age sd_age n_values monolingual 27.96 6.78 55 bilingual 31.93 9.44 45 2.6 Bar chart of counts For our first plot, we will make a simple bar chart of counts that shows the number of participants in each language group. ggplot(data = dat, mapping = aes(x = language)) + geom_bar() Figure 2.1: Bar chart of counts. The first line of code sets up the base of the plot. data specifies which data source to use for the plot mapping specifies which variables to map to which aesthetics (aes) of the plot. Aesthetic mappings describe how variables in the data are mapped to visual properties (aesthetics) of geoms. x specifies which variable to put on the x-axis The second line of code adds a geom, and is connected to the base code with +. In this case, we ask for geom_bar(). Each geom has an associated default statistic. For geom_bar(), the default statistic is to count the data passed to it. This means that you do not have to specify a y variable when making a bar plot of counts; when given an x variable geom_bar() will automatically calculate counts of the groups in that variable. In this example, it counts the number of data points that are in each category of the language variable. The base layer and the geoms you add as layers work in symbiosis so it is worthwhile checking the mapping rules as these are related to the default statistic for the plot’s geom. 2.7 Plotting existing aggregates and percent If your data already have the counts that you want to plot, you can set stat=\"identity\" inside of geom_bar() to use that number instead of counting rows. For example, there is currently no function to plot percentages rather than counts within ggplot, you need to calculate these and store them in an object which is then used as the dataset. Notice that we are now omitting the names of the arguments data and mapping in the ggplot() function. dat_percent &lt;- dat %&gt;% group_by(language) %&gt;% count() %&gt;% ungroup() %&gt;% mutate(percent = (n/sum(n)*100)) ggplot(dat_percent, aes(x = language, y = percent)) + geom_bar(stat=&quot;identity&quot;) Figure 2.2: Bar chart of pre-calculated counts. 2.8 Histogram The code to plot a histogram of age is very similar to the code used for the bar chart. We start by setting up the plot space, the dataset we want to use, and mapping the variables to the relevant axis. In this case, we want to plot a histogram with age on the x-axis: ggplot(dat, aes(x = age)) + geom_histogram() Figure 2.3: Histogram of ages. The base statistic for geom_histogram() is also count, and by default geom_histogram() divides the x-axis into “bins” and counts how many observations are in each bin and so the y-axis does not need to be specified. When you run the code to produce the histogram, you will get the message stat_bin() using bins = 30. Pick better value with binwidth. This means that the default number of bins geom_histogram() divided the x-axis into is 30. For our data that looks appropriate, but for example, if you want one bar to equal 5 years, you can adjust binwidth = 5. ggplot(dat, aes(x = age)) + geom_histogram(binwidth = 5) Figure 2.4: Histogram of ages where each bin covers five years. 2.9 Customisation 1 So far we have made basic plots with the default visual appearance. Before we move on to the experimental data we will introduce some simple visual customisation options. There are many ways in which you can control or customise the visual appearance of figures in R. However, once you understand the logic of one, it becomes easier to understand others that you may see in other examples. Visual appearance of elements can be customised within a geom itself, within the aesthetic mapping, or by connecting additional layers with +. In this section we look at the simplest and most commonly-used customisations: changing colours, adding axis labels, and adding themes. 2.9.1 Changing colours For our basic bar chart, you can control colours used to display the bars by setting fill (internal colour) and colour (outline colour) inside the geom function. This methods changes all the bars; we will show you later how to set fill or colour separately for different groups. ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, colour = &quot;black&quot;) Figure 2.5: Histogram with custom colors for bar fill and line colors. 2.9.2 Editing axis names and labels To edit axis names and labels you can connect scale_* functions to your plot with + to add layers. These functions are part of ggplot and the one you use depends on which aesthetic you wish to edit (e.g., x-axis, y-axis, fill, colour) as well as the type of data it represents (discrete, continuous). For the bar chart of counts, the x-axis is mapped to a discrete (categorical) variable whilst the y-axis is continuous. For each of these there is a relevant scale function with various elements that can be customised. Each axis then has its own function added as a layer to the basic plot. ggplot(dat, aes(language)) + geom_bar() + scale_x_discrete(name = &quot;Language group&quot;, labels = c(&quot;Monolingual&quot;, &quot;Bilingual&quot;)) + scale_y_continuous(name = &quot;Number of participants&quot;, breaks = c(0,10,20,30,40,50)) Figure 2.6: Bar chart with custom axis labels. name controls the overall name of the axis (note the use of quotation marks) labels controls the names of the conditions with a discrete variable. c() is a function that you will see in many different contexts and is used to combine multiple values. In this case, the labels we want to apply are combined within c() by enclosing each word within their own parenthesis, and are in the order displayed on the plot. A very common error is to forget to enclose multiple values in c(). breaks controls the tick marks on the axis. Again because there are multiple values, they are enclosed within c() although because they are numeric and not text, they do not need quotation marks. 2.9.3 Discrete vs. continuous errors Another very common error is to map the wrong type of scale_ function to a variable. Try running the below code: # produces an error ggplot(dat, aes(language)) + geom_bar() + scale_x_continuous(name = &quot;Language group&quot;, labels = c(&quot;Monolingual&quot;, &quot;Bilingual&quot;)) This will produce the error Discrete value supplied to continuous scale because we have used a continuous scale function, despite the fact that x-axis variable is discrete. If you get this error (or the reverse), check the type of data on each axis and the function you have used. 2.9.4 Adding a theme ggplot has a number of built-in visual themes that you can apply as an extra layer. The below code updates the x-axis and y-axis labels to the histogram, but also applies theme_minimal(). Each part of a theme can be independently customised, which may be necessary, for example, if you have journal guidelines on fonts for publication. There are further instructions for how to do this in the additional resources. ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_minimal() Figure 2.7: Histogram with a custom theme. You can set the theme globally so that all subsequent plots use a theme. theme_set(theme_minimal()) If you wished to return to the default theme, change the above to specify theme_grey(). 2.10 Activities 1 Before you move on try the following: Add a layer that edits the name of the y-axis histogram label to Number of participants. Solution 1 ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_minimal() + scale_y_continuous(name = &quot;Number of participants&quot;) Change the colour of the bars in the bar chart to red. Solution 2 ggplot(data = dat, mapping = aes(x = language)) + geom_bar(fill = &quot;red&quot;) Remove theme_minimal() from the histogram and instead apply one of the other available themes. To find out about other available themes, start typing theme_ and the auto-complete will show you the available options - this will only work if you have loaded the tidyverse library with library(tidyverse). Solution 3 #multiple options here e.g., theme_classic() ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_classic() # theme_bw() ggplot(dat, aes(age)) + geom_histogram(binwidth = 1, fill = &quot;wheat&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Participant age (years)&quot;) + theme_bw() "],["transforming-data.html", "Chapter 3 Transforming Data 3.1 Data formats 3.2 Transforming data 3.3 Histogram 2 3.4 Density plots 3.5 Scatterplots 3.6 Transforming data 2 3.7 Customisation 2 3.8 Activities 2", " Chapter 3 Transforming Data 3.1 Data formats To visualise the experimental reaction time and accuracy data using ggplot, we first need to reshape the data from wide-format to long-format and it is this step that can cause friction with novice users of R. Traditionally, psychologists have been taught data skills using wide-format data. Wide-format data typically has one row of data for each participant with separate columns for each score or variable. Where there are repeated-measures variables, the dependent variable is split across different columns with one measurement for each condition and where there is between groups variables, a separate column is added to encode the group to which a participant or observation belongs. The simulated lexical decision data is currently in wide-format (see Table 3.1) where each participant’s aggregated4 reaction time and accuracy for each level of the within-subject variable is split across multiple columns. Table 3.1: Data in wide format. id age language rt_word rt_nonword acc_word acc_nonword S001 22 monolingual 379.46 516.82 99 90 S002 33 monolingual 312.45 435.04 94 82 S003 23 monolingual 404.94 458.50 96 87 S004 28 monolingual 298.37 335.89 92 76 S005 26 monolingual 316.42 401.32 91 83 S006 29 monolingual 357.17 367.34 96 78 Wide-format is popular because it is intuitive to read and easy to enter data into as all the data for one participant is contained within a single row. However, for the purposes of analysis, and particularly for analysis using R, this format is unsuitable. Whilst it is intuitive to read by a human, the same is not true for a computer. Wide-format data concatenates multiple pieces of information in a single column, for example in Table 3.1, rt_word contains information related to both a DV and one level of an IV. In comparison, long-format data separates the DV from the IV’s so that each column represents only one variable. The less intuitive part is that long data has multiple rows for each participant and a column that encodes the level of the IV (word or nonword). In essence, the long-format encodes repeated-measures variable in the same way as a between-group variable in SPSS. Wickham (2014) provides a comprehensive overview of the benefits of a similar format known as tidy data, which is a standard way of mapping a dataset to its structure, but for the purposes of this tutorial there are two important rules: each column should be a variable and each row should be an observation. Moving from using wide-form to long-form datasets can require a conceptual shift on the part of the researcher and one that usually only comes with practice and repeated exposure5. For our example dataset, adhering to these rules for reshaping the data would produce Table 3.2. Rather than different observations of the same dependent variable being split across columns, there is now a single column for the DV reaction time, and a single column for the DV accuracy. Each participant now has multiple rows of data, one for each observation (i.e., for each participant there will be as many rows as there are levels of the within-subject IV). Although there is some repetition of age and language group, each row is unique when looking at the combination of measures. Table 3.2: Data in the correct format for visualization. id age language condition rt acc S001 22 monolingual word 379.46 99 S001 22 monolingual nonword 516.82 90 S002 33 monolingual word 312.45 94 S002 33 monolingual nonword 435.04 82 S003 23 monolingual word 404.94 96 S003 23 monolingual nonword 458.50 87 The benefits and flexibility of this format will hopefully become apparent as we progress through the tutorial, however, a useful rule of thumb when working with data in R for visualisation is that anything that shares an axis should probably be in the same column. For example, a simple bar chart of means for the reaction time DV would display the variable condition on the x-axis with bars representing both the word and nonword data, therefore, these data should be in one column and not split. 3.2 Transforming data We have chosen a 2 x 2 design with two DVs as we anticipate that this is a design many researchers will be familiar with and may also have existing datasets with a similar structure. However, it is worth normalising that trial-and-error is part of the process of learning how to apply these functions to new datasets and structures. Data visualisation can be a useful way to scaffold learning these data transformations because they can provide a concrete visual check as to whether you have done what you intended to do with your data. 3.2.1 Step 1: pivot_longer() The first step is to use the function pivot_longer() to transform the data to long-form. We have purposefully used a more complex dataset with two DVs for this tutorial to aid researchers applying our code to their own datasets. Because of this, we will break down the steps involved to help show how the code works. This first code ignores that the dataset has two DVs, a problem we will fix in step 2. The pivot functions can be easier to show than tell - you may find it a useful exercise to run the below code and compare the newly created object long (Table 3.3) with the original dat Table 3.1 before reading on. long &lt;- pivot_longer(data = dat, cols = rt_word:acc_nonword, names_to = &quot;dv_condition&quot;, values_to = &quot;dv&quot;) As with the other tidyverse functions, the first argument specifies the dataset to use as the base, in this case dat. This argument name is often dropped in examples. cols specifies all the columns you want to transform. The easiest way to visualise this is to think about which columns would be the same in the new long-form dataset and which will change. If you refer back to Table 3.1, you can see that id, age, and language all remain, while the columns that contain the measurements of the DVs change. The colon notation first_column:last_column is used to select all variables from the first column specified to the second. In our code, cols specifies that the columns we want to transform are rt_word to acc_nonword. names_to specifies the name of the new column that will be created. Finally, values_to names the new column that will contain the measurements, in this case we’ll call it dv. At this point you may find it helpful to go back and compare dat and long again to see how each argument matches up with the output of the table. Table 3.3: Data in long format with mixed DVs. id age language dv_condition dv S001 22 monolingual rt_word 379.46 S001 22 monolingual rt_nonword 516.82 S001 22 monolingual acc_word 99.00 S001 22 monolingual acc_nonword 90.00 S002 33 monolingual rt_word 312.45 S002 33 monolingual rt_nonword 435.04 3.2.2 Step 2: pivot_longer() adjusted The problem with the above long-form data-set is that because we have ignored that there are two DVs, dv_condition still continues to conflate two variables - it has information about the type of DV and the condition of the IV. To account for this, we include a new argument names_sep and adjust name_to to specify the creation of two new columns. Note that we are pivoting the same wide-format dataset dat as we did in step 1. names_sep specifies how to split up the variable name in cases where it has multiple components. This is when taking care to name your variables consistently and meaningfully pays off. Because the word to the left of the separator (_) is always the DV type and the word to the right is always the condition of the within-subject IV, it is easy to automatically split the columns. Note that when specifying more than one column name, they must be combined using c() and be enclosed in their own quotation marks. long2 &lt;- pivot_longer(data = dat, cols = rt_word:acc_nonword, names_sep = &quot;_&quot;, names_to = c(&quot;dv_type&quot;, &quot;condition&quot;), values_to = &quot;dv&quot;) Table 3.4: Data in long format with dv type and condition in separate columns. id age language dv_type condition dv S001 22 monolingual rt word 379.46 S001 22 monolingual rt nonword 516.82 S001 22 monolingual acc word 99.00 S001 22 monolingual acc nonword 90.00 S002 33 monolingual rt word 312.45 S002 33 monolingual rt nonword 435.04 3.2.3 Step 3: pivot_wider() Although we have now split the columns so that there are separate variables for the DV type and level of condition, because we have two DVs, there is an additional bit of wrangling required to get the data in the right format for plotting. In the current long-form dataset, the column dv contains both reaction time and accuracy measures and keeping in mind the rule of thumb that anything that shares an axis should probably be in the same column, this creates a problem because we cannot plot two different units of measurement on the same axis. To fix this we need to use the function pivot_wider(). Again, we would encourage you at this point to compare long2 and dat_long with the below code to try and map the connections before reading on. dat_long &lt;- pivot_wider(long2, names_from = &quot;dv_type&quot;, values_from = &quot;dv&quot;) The first argument is again the dataset you wish to work from, in this case long2. We have removed the argument name data in this example. names_from acts somewhat like the reverse of names_to from pivot_longer(). It will take the values from the variable specified and use these as variable names, i.e., in this case, the values of rt and acc that are currently in the dv_type column, and turn these into the column names. Finally, values_from specifies the values to fill the new columns with. In this case, the new columns rt and acc will be filled with the values that were in dv. Again, it can be helpful to compare each dataset with the code to see how it aligns. This final long-form data should look like Table 3.2. If you are working with a dataset with only one DV, note that only step 1 of this process would be necessary. Also, be careful not to calculate demographic descriptive statistics from this long-form dataset. Because the process of transformation has introduced some repetition for these variables, the wide-form dataset where 1 row = 1 participant should be used for demographic information. Finally, the three step process noted above is broken down for teaching purposes, in reality, one would likely do this in a single pipeline of code, for example: dat_long &lt;- pivot_longer(data = dat, cols = rt_word:acc_nonword, names_sep = &quot;_&quot;, names_to = c(&quot;dv_type&quot;, &quot;condition&quot;), values_to = &quot;dv&quot;) %&gt;% pivot_wider(names_from = &quot;dv_type&quot;, values_from = &quot;dv&quot;) 3.3 Histogram 2 Now that we have the experimental data in the right form, we can begin to create some useful visualizations. First, to demonstrate how code recipes can be reused and adapted, we will create histograms of reaction time and accuracy. The below code uses the same template as before but changes the dataset (dat_long), the bin-widths of the histograms, the x variable to display (rt/acc), and the name of the x-axis. ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, fill = &quot;white&quot;, colour = &quot;black&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, colour = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) Figure 3.1: Histograms showing the distribution of reaction time (top) and accuracy (bottom) 3.4 Density plots The layer system makes it easy to create new types of plots by adapting existing recipes. For example, rather than creating a histogram, we can create a smoothed density plot by calling geom_density() rather than geom_histogram(). The rest of the code remains identical. ggplot(dat_long, aes(x = rt)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) Figure 3.2: Density plot of reaction time. 3.4.1 Grouped density plots Density plots are most useful for comparing the distributions of different groups of data. Because the dataset is now in long format, it makes it easier to map another variable to the plot because each variable is contained within a single column. In addition to mapping rt to the x-axis, we specify the fill aesthetic to fill the visualisation of each level of the condition variable with different colours. As with the x and y-axis scale functions, we can edit the names and labels of our fill aesthetic by adding on another scale_* layer. Note that the fill here is set inside the aes() function, which tells ggplot to set the fill differently for each value in the condition column. You cannot specify which colour here (e.g., fill=\"red\"), like you could when you set fill inside the geom_*() function before. ggplot(dat_long, aes(x = rt, fill = condition)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Condition&quot;, labels = c(&quot;Word&quot;, &quot;Non-word&quot;)) Figure 3.3: Density plot of reaction times grouped by condition. 3.5 Scatterplots Scatterplots are created by calling geom_point() and require both an x and y variable to be specified in the mapping. ggplot(dat_long, aes(x = rt, y = age)) + geom_point() Figure 3.4: Point plot of reaction time versus age. A line of best fit can be added with an additional layer that calls the function geom_smooth(). The default is to draw a LOESS or curved regression line, however, a linear line of best fit can be specified using method = \"lm\". By default, geom_smooth() will also draw a confidence envelope around the regression line, this can be removed by adding se = FALSE to geom_smooth(). A common error is to try and use geom_line() to draw the line of best fit, which whilst a sensible guess, will not work (try it). ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Figure 3.5: Line of best fit for reaction time versus age. 3.5.1 Grouped scatterplots Similar to the density plot, the scatterplot can also be easily adjusted to display grouped data. For geom_point(), the grouping variable is mapped to colour rather than fill and the relevant scale_ function is added. ggplot(dat_long, aes(x = rt, y = age, colour = condition)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_colour_discrete(name = &quot;Condition&quot;, labels = c(&quot;Word&quot;, &quot;Non-word&quot;)) Figure 3.6: Grouped scatter plot of reaction time versus age by condition. 3.6 Transforming data 2 Following the rule that anything that shares an axis should probably be in the same column means that we will frequently need our data in long-form when using ggplot2, however, there are some cases when wide-form is necessary. For example, we may wish to visualise the relationship between reaction time in the word and non-word conditions. The easiest way to achieve this in our case would simply be to use the original wide-form data as the input: ggplot(dat, aes(x = rt_word, y = rt_nonword, colour = language)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Figure 3.7: Scatterplot with data grouped by langauge group However, there may also be cases when you do not have an original wide-form version and you can use the pivot_wider() function to transform from long to wide. dat_wide &lt;- dat_long %&gt;% pivot_wider(id_cols = &quot;id&quot;, names_from = &quot;condition&quot;, values_from = c(rt,acc)) id rt_word rt_nonword acc_word acc_nonword S001 379.4585 516.8176 99 90 S002 312.4513 435.0404 94 82 S003 404.9407 458.5022 96 87 S004 298.3734 335.8933 92 76 S005 316.4250 401.3214 91 83 S006 357.1710 367.3355 96 78 3.7 Customisation 2 3.7.1 Accessible colour schemes One of the drawbacks of using ggplot for visualisation is that the default colour scheme is not accessible (or visually appealing). The red and green default palette is difficult for colour-blind people to differentiate, and also does not display well in grey scale. You can specify exact custom colours for your plots, but one easy option is to use a colour palette and the viridis scale functions call such a palette. These take the same arguments as their default scale sister functions for updating axis names and labels, but display plots in contrasting colours that can be read by colour-blind people and that also print well in grey scale. The viridis scale functions provide a number of different options for the colour - try setting option to any letter from A - E to see the different sets. ggplot(dat_long, aes(x = rt, y = age, colour = condition)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + # use &quot;viridis_d&quot; instead of &quot;discrete&quot; for better colours scale_colour_viridis_d(name = &quot;Condition&quot;, labels = c(&quot;Word&quot;, &quot;Non-word&quot;), option = &quot;E&quot;) Figure 3.8: Use the viridis colour scheme for accessibility. 3.8 Activities 2 Before you move on try the following: Use fill to created grouped histograms that display the distributions for rt for each language group separately and also edit the fill axis labels. Try adding position = \"dodge\" to geom_histogram() to see what happens. Solution 1 # fill and axis changes ggplot(dat_long, aes(x = rt, fill = language)) + geom_histogram(binwidth = 10) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Group&quot;, labels = c(&quot;Monolingual&quot;, &quot;Bilingual&quot;)) # add in dodge ggplot(dat_long, aes(x = rt, fill = language)) + geom_histogram(binwidth = 10, position = &quot;dodge&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Group&quot;, labels = c(&quot;Monolingual&quot;, &quot;Bilingual&quot;)) Use scale_*_*() functions to edit the name of the x and y-axis on the scatterplot Solution 2 ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(name = &quot;Reaction time&quot;) + scale_y_continuous(name = &quot;Age&quot;) Use se = FALSE to remove the confidence envelope from the scatterplots Solution 3 ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_x_continuous(name = &quot;Reaction time&quot;) + scale_y_continuous(name = &quot;Age&quot;) Remove method = \"lm\" from geom_smooth() to produce a curved regression line. Solution 4 ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth() + scale_x_continuous(name = &quot;Reaction time&quot;) + scale_y_continuous(name = &quot;Age&quot;) Replace the default scale_fill_*() on the grouped density plot with the colour-blind friendly version. Solution ggplot(dat_long, aes(x = rt, fill = condition)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_viridis_d(option = &quot;E&quot;, name = &quot;Condition&quot;, labels = c(&quot;Word&quot;, &quot;Non-word&quot;)) References "],["representing-summary-statistics.html", "Chapter 4 Representing Summary Statistics 4.1 Boxplots 4.2 Violin plots 4.3 Bar chart of means 4.4 Violin-boxplot 4.5 Customisation part 3 4.6 Activities 3", " Chapter 4 Representing Summary Statistics The layering approach that is used in ggplot to make figures comes into its own when you want to include information about the distribution and spread of scores. In this section we introduce different ways of including summary statistics on your figures. 4.1 Boxplots As with geom_point(), the boxplot geom also require an x and y-variable to be specified. In this case, x must be a discrete, or categorical variable, whilst y must be continuous. ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() Figure 4.1: Basic boxplot. 4.1.1 Grouped boxplots As with histograms and density plots, fill can be used to create grouped boxplots. This looks like a lot of complicated code at first glance, but most of it is just editing the axis labels. ggplot(dat_long, aes(x = condition, y = acc, fill = language)) + geom_boxplot() + scale_fill_viridis_d(option = &quot;E&quot;, name = &quot;Group&quot;, labels = c(&quot;Bilingual&quot;, &quot;Monolingual&quot;)) + theme_classic() + scale_x_discrete(name = &quot;Condition&quot;, labels = c(&quot;Word&quot;, &quot;Non-word&quot;)) + scale_y_continuous(name = &quot;Accuracy&quot;) Figure 4.2: Grouped boxplots 4.2 Violin plots Violin plots display the distribution of a dataset and can be created by calling geom_violin(). They are so-called because the shape they make sometimes looks something like a violin. They are essentially a mirrored density plot on its side. Note that the below code is identical to the code used to draw the boxplots above, except for the call to geom_violin() rather than geom_boxplot(). ggplot(dat_long, aes(x = condition, y = acc, fill = language)) + geom_violin() + scale_fill_viridis_d(option = &quot;D&quot;, name = &quot;Group&quot;, labels = c(&quot;Bilingual&quot;, &quot;Monolingual&quot;)) + theme_classic() + scale_x_discrete(name = &quot;Condition&quot;, labels = c(&quot;Word&quot;, &quot;Non-word&quot;)) + scale_y_continuous(name = &quot;Accuracy&quot;) Figure 4.3: Violin plot. 4.3 Bar chart of means Commonly, rather than visualising distributions of raw data researchers will wish to visualise means using a bar chart with error bars. As with SPSS and Excel, ggplot requires you to calculate the summary statistics and then plot the summary. There are at least two ways to do this, in the first you make a table of summary statistics as we did earlier when calculating the participant demographics and then plot that table. The second approach is to calculate the statistics within a layer of the plot. That is the approach we will use below. First we present code for making a bar chart. The code for bar charts is here because it is a common visualisation that is familiar to most researchers, however, we would urge you to use a visualisation that provides more transparency about the distribution of the raw data, such as the violin-boxplots we will present in the next section. To summarise the data into means we use a new function stat_summary. Rather than calling a geom_* function, we call stat_summary() and specify how we want to summarise the data and how we want to present that summary in our figure. fun specifies the summary function that gives us the y-value we want to plot, in this case, mean. geom specifies what shape or plot we want to use to display the summary. For the first layer we will specify bar. As with the other geom-type functions we have shown you, this part of the stat_summary() function is tied to the aesthetic mapping in the first line of code. The underlying statistics for a bar chart means that we must specify and IV (x-axis) as well as the DV (y-axis). ggplot(dat_long, aes(x = condition, y = rt)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;bar&quot;) Figure 4.4: Bar plot of means. To add the error bars, another layer is added with a second call to stat_summary. This time, the function represents the type of error bars we wish to draw, you can choose from mean_se for standard error, mean_cl_normal for confidence intervals, or mean_sdl for standard deviation. width controls the width of the error bars - try changing the value to see what happens. Whilst fun returns a single value (y) per condition, fun.data returns the y-values we want to plot plus their minimum and maximum values, in this case, mean_se ggplot(dat_long, aes(x = condition, y = rt)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;bar&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2) Figure 4.5: Bar plot of means with error bars representing SE. 4.4 Violin-boxplot The power of the layered system for making figures is further highlighted by the ability to combine different types of plots. For example, rather than using a bar chart with error bars, one can easily create a single plot that includes density of the distribution, confidence intervals, means and standard errors. In the below code we first draw a violin plot, then layer on a boxplot, a point for the mean (note geom = \"point\" instead of \"bar\") and standard error bars (geom = \"errorbar\"). This plot does not require much additional code to produce than the bar plot with error bars, yet the amount of information displayed is vastly superior. fatten = NULL in the boxplot geom removes the median line, which can make it easier to see the mean and error bars. Including this argument will result in the warning message Removed 1 rows containing missing values (geom_segment) and is not a cause for concern. Removing this argument will reinstate the median line. ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + # remove the median line with fatten = NULL geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) Figure 4.6: Violin-boxplot with mean dot and standard error bars. It is important to note that the order of the layers matters and it is worth experimenting with the order to see where the order matters. For example, if we call geom_boxplot() followed by geom_violin(), we get the following mess: ggplot(dat_long, aes(x = condition, y= rt)) + geom_boxplot() + geom_violin() + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) Figure 4.7: Plot with the geoms in the wrong order. 4.4.1 Grouped violin-boxplots As with previous plots, another variable can be mapped to fill for the violin-boxplot. However, simply adding fill to the mapping causes the different components of the plot to become misaligned because they have different default positions: ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) Figure 4.8: Grouped violin-boxplots without repositioning. To rectify this we need to adjust the argument position for each of the misaligned layers. position_dodge() instructs R to move (dodge) the position of the plot component by the specified value - finding what value you need can sometimes take trial and error. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) Figure 4.9: Grouped violin-boxplots with repositioning. 4.5 Customisation part 3 Combining multiple type of plots can present an issue with the colours, particularly when the viridis scheme is used - in the below example it is hard to make out the black lines of the boxplot and the mean/error bars. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 4.10: A color scheme that makes lines difficult to see. There are a number of solutions to this problem. First, we can change the colour of individual geoms by adding colour = \"colour\" to each relevant geom: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, colour = &quot;grey&quot;) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, colour = &quot;grey&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, colour = &quot;grey&quot;) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 4.11: Manually changing the line colors. We can also keep the original colours but adjust the transparency of each layer using alpha. Again, the exact values needed can take trial and error: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 4.12: Using transparency on the fill color. 4.6 Activities 3 Before you go on, do the following: Review all the code you have run so far. Try to identify the commonalities between each plot’s code and the bits of the code you might change if you were using a different dataset. Take a moment to recognise the complexity of the code you are now able to read. For the violin-boxplot, for geom = \"point\", try changing fun to median Solution ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + # remove the median line with fatten = NULL geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;median&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) For the violin-boxplot, for geom = \"errorbar\", try changing fun.data to mean_cl_normal (for 95% CI) Solution ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + # remove the median line with fatten = NULL geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_cl_normal&quot;, geom = &quot;errorbar&quot;, width = .1) Go back to the grouped density plots and try changing the transparency with alpha. Solution ggplot(dat_long, aes(x = rt, fill = condition)) + geom_density(alpha = .4)+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + scale_fill_discrete(name = &quot;Condition&quot;, labels = c(&quot;Word&quot;, &quot;Non-word&quot;)) "],["multi-part-plots.html", "Chapter 5 Multi-part Plots 5.1 Interaction plots 5.2 Combined interaction plots 5.3 Facets 5.4 Storing plots 5.5 Saving plots as images 5.6 Multiple plots 5.7 Customisation part 4 5.8 Activities 4", " Chapter 5 Multi-part Plots 5.1 Interaction plots Interaction plots are commonly used to help display or interpret a factorial design. Just as with the bar chart of means, interaction plots represent data summaries and so they are built up with a series of calls to stat_summary(). shape acts much like fill in previous plots, except that rather than producing different colour fills for each level of the IV, the data points are given different shapes. size lets you change the size of lines and points. You usually don’t want different groups to be different sizes, so this option is set inside the relevant geom_*() function, not inside the aes() function. scale_color_manual() works much like scale_color_discrete() except that it lets you specify the colour values manually, instead of then being automatically applied based on the palette you choose/default to. You can specify RGB colour values or a list of predefined colour names - all available options can be found by running colours() in the console. Other manual scales are also available, for example, scale_fill_manual. ggplot(dat_long, aes(x = condition, y = rt, shape = language, group = language, color = language)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 3) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2) + scale_color_manual(values = c(&quot;blue&quot;, &quot;darkorange&quot;)) + theme_classic() Figure 5.1: Interaction plot. 5.2 Combined interaction plots A more complex interaction plot can be produced that takes advantage of the layers to visualise not only the overall interaction, but the change across conditions for each participant. This code is more complex than all prior code because it does not use a universal mapping of the plot aesthetics. In our code so far, the aesthetic mapping (aes) of the plot has been specified in the first line of code as all layers have used the same mapping, however, is is also possible for each layer to use a different mapping. The first call to ggplot() sets up the default mappings of the plot that will be used unless otherwise specified - the x, y and group variable. Note two additions are shape and linetype that will vary those elements according to the language variable. geom_point() overrides the default mapping by setting its own colour to draw the data points from each language group in a different colour. alpha is set to a low value to aid readability. Note that because the aesthetic override was defined within the geom function, the colours are not represented in the legend. Similarly, geom_line() overrides the default grouping variable so that a line is drawn to connect the individual data points for each participant (group = id) rather than each language group, and also sets the colours. The default line type is also overridden and set for all lines to be solid. Finally, the calls to stat_summary() remain largely as they were, with the exception of setting colour = \"black\" and size = 2 so that the overall means and error bars can be more easily distinguished from the individual data points. Because they do not specify an individual mapping, they use the defaults (e.g., the lines are connected by language group). For the error bars the lines are again made solid. ggplot(dat_long, aes(x = condition, y = rt, group = language, shape = language)) + geom_point(aes(colour = language),alpha = .2) + geom_line(aes(group = id, colour = language), alpha = .2) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 2, colour = &quot;black&quot;) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;, colour = &quot;black&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2, colour = &quot;black&quot;) + theme_minimal() Figure 5.2: Interaction plot with by-participant data 5.3 Facets So far we have produced single plots that display all the desired variables in one, however, there are situations in which it may be useful to create separate plots for each level of a variable. The below code is an adaptation of the code used to produce the grouped scatterplot (see Figure 4.8) in which it may be easier to see how the relationship changes when the data are not overlaid. Rather than using colour = condition to produce different colours for each level of condition, this variable is instead passed to facet_wrap(). ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~condition) Figure 5.3: Faceted scatterplot As another example, we can use facet_wrap() as an alternative to the grouped violin-boxplot (see Figure 4.9) in which the variable language is passed to facet_wrap() rather than fill. ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language) + theme_minimal() Figure 5.4: Facted violin-boxplot Finally, note that editing the labels for faceted variables uses the labeller function, calling it within facet_wrap. labeller uses syntax that is different from what we have shown you up to now. Syntax simply refers to the rules about the words that a function uses. In the exercise about looking for the underlying rules to the code from the previous chapter you likely tapped into the rules for the various ggplot functions. However, once in a while you will come across something that just does not follow the rules you have been building on and labeller is an example of that. Before we explain it, read the below code and see if you can figure out the syntactic rules for the function. ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller( language = c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;))) + theme_minimal() Figure 5.5: Faceted violin-boxplot with updated labels Even though the labeller syntax is new, it is still fairly logical, for each level of the variable you want to facet by, you need to specify a label, so you call the variable by naming it: labeller = labeller(language = then you make a list of the levels (monolingual and bilingual) and for each you tell the function its new name c(monolingual = \"Monolingual participants\", bilingual = \"Bilingual participants\"). 5.4 Storing plots Just like with datasets, plots can be saved to objects. The below code saves the histograms we produced for reaction time and accuracy to objects named p1 and p2. These plots can then be viewed by calling the object name in the console. p1 &lt;- ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, color = &quot;black&quot;) p2 &lt;- ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, color = &quot;black&quot;) Importantly, layers can then be added to these saved objects. For example, the below code adds a theme to the plot saved in p1 and saves it as a new object p3. This is important because many of the examples of ggplot code you will find in online help forums use the p + format to build up plots but fail to explain what this means, which can be confusing to beginners. p3 &lt;- p1 + theme_minimal() 5.5 Saving plots as images In addition to saving plots to objects for further use in R, the function ggsave() can be used to save plots as images on your hard drive. The only required argument for ggsave is the file name of the image file you will create, complete with file extension (this can be “eps,” “ps,” “tex,” “pdf,” “jpeg,” “tiff,” “png,” “bmp,” “svg” or “wmf”). By default, ggsave() will save the last plot displayed, however, you can also specify a specific plot object if you have one saved. ggsave(filename = &quot;my_plot.png&quot;) # save last displayed plot ggsave(filename = &quot;my_plot.png&quot;, plot = p3) # save plot p3 The width, height and resolution of the image can all be manually adjusted and the help documentation for is useful here (type ?ggsave in the console to access the help). 5.6 Multiple plots As well as creating separate plots for each level of a variable using facet_wrap(), you may also wish to display multiple different plots together and the patchwork package provides an intuitive way to do this. patchwork does not require the use of any functions once it is loaded with library(patchwork), you simply need to save the plots you wish to combine to objects as above and use the operators +, / () and | to specify the look of the final figure. 5.6.1 Combining two plots Two plots can be combined side-by-side or stacked on top of each other. These combined plots could also be saved to an object and then passed to ggsave. p1 + p2 # side-by-side Figure 5.6: Side-by-side plots with patchwork p1 / p2 # stacked Figure 5.7: Stacked plots with patchwork 5.6.2 Combining three or more plots Three or more plots can be combined in a number of ways and the patchwork syntax is relatively easy to grasp with a few examples and a bit of trial and error. First, we save the complex interaction plot and faceted violin-boxplot to objects named p5 and p6. p5 &lt;- ggplot(dat_long, aes(x = condition, y = rt, group = language, shape = language)) + geom_point(aes(colour = language),alpha = .2) + geom_line(aes(group = id, colour = language), alpha = .2) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 2, colour = &quot;black&quot;) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;, colour = &quot;black&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2, colour = &quot;black&quot;) + theme_minimal() p6 &lt;- ggplot(dat_long, aes(x = condition, y= rt)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller( language = (c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;)))) + theme_minimal() The exact layout of your plots will depend upon a number of factors. Try running the below examples and adjust the use of the operators to see how they change the layout. Each line of code will draw a different figure. p1 /p5 / p6 (p1 + p6) / p5 p6 | p1 / p5 5.7 Customisation part 4 5.7.1 Axis labels Previously when we edited the main axis labels we used the scale_ functions to do so. These functions are useful to know because they allow you to customise each aspect of the scale, for example, the breaks and limits. However, if you only need to change the main axis name, there is a quicker way to do so using labs(). The below code adds a layer to the plot that changes the axis labels for the histogram saved in p1 and adds a title and subtitle. The title and subtitle do not conform to APA standards (more on APA formatting in the additional resources), however, for presentations and social media they can be useful. p5 + labs(x = &quot;Type of word&quot;, y = &quot;Reaction time (ms)&quot;, title = &quot;Language group by word type interaction plot&quot;, subtitle = &quot;Reaction time data&quot;) Figure 5.8: Plot with edited labels and title You can also use labs() to remove axis labels, for example, try adjusting the above code to x = NULL. 5.7.2 Redundant aesthetics So far when we have produced plots with colours, the colours were the only way that different levels of a variable were indicated, but it is sometimes preferable to indicate levels with both colour and other means, such as facets or x-axis categories. The code below adds fill = language to the violin-boxplots that are also faceted by language. We adjust alpha and use the viridis colour palette to customise the colours. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .6) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller( language = (c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;)))) + theme_minimal() + scale_fill_viridis_d(option = &quot;E&quot;) Figure 5.9: Violin-boxplot with redundant legend Specifying a fill variable means that by default, R produces a legend for that variable. However, the use of colour is redundant with the facet labels, so you can remove this legend with the guides function. ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .6) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + facet_wrap(~language, labeller = labeller(language = (c(monolingual = &quot;Monolingual participants&quot;, bilingual = &quot;Bilingual participants&quot;)))) + theme_minimal() + scale_fill_viridis_d(option = &quot;E&quot;) + guides(fill = FALSE) Figure 5.10: Plot with suppressed redundant legend 5.8 Activities 4 Before you go on, do the following: Rather than mapping both variables (condition and language) to a single interaction plot with individual participant data, instead produce a faceted plot that separates the monolingual and bilingual data. All visual elements should remain the same (colours and shapes) and you should also take care not to have any redundant legends. Solution ggplot(dat_long, aes(x = condition, y = rt, group = language, shape = language)) + geom_point(aes(colour = language),alpha = .2) + geom_line(aes(group = id, colour = language), alpha = .2) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 2, colour = &quot;black&quot;) + stat_summary(fun = &quot;mean&quot;, geom = &quot;line&quot;, colour = &quot;black&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .2, colour = &quot;black&quot;) + theme_minimal() + facet_wrap(~language) + guides(shape = FALSE, colour = FALSE) # this wasn&#39;t easy so if you got it, well done! Choose your favourite three plots you’ve produced so far in this tutorial, tidy them up with axis labels, your preferred colour scheme, and any necessary titles, and then combine them using patchwork. If you’re feeling particularly proud of them, post them on Twitter using #PsyTeachR. "],["advanced-plots.html", "Chapter 6 Advanced Plots 6.1 Split-violin plots 6.2 Raincloud plots 6.3 Ridge plots 6.4 Alluvial plots", " Chapter 6 Advanced Plots This tutorial has but scratched the surface of the visualisation options available using R - in the additional online resources we provide some further advanced plots and customisation options for those readers who are feeling confident with the content covered in this tutorial, however, the below plots give an idea of what is possible, and represent the favourite plots of the authorship team. We will use some custom functions: geom_split_violin() and geom_flat_violin(), which you can access through the introdataviz package. These functions are modified from (Allen et al. 2021). # how to install the introdataviz package to get split and half violin plots devtools::install_github(&quot;psyteachr/introdataviz&quot;) 6.1 Split-violin plots Split-violin plots remove the redundancy of mirrored violin plots and make it easier to compare the distributions between multiple conditions. ggplot(dat_long, aes(x = condition, y = rt, fill = language)) + introdataviz::geom_split_violin(alpha = .4, trim = FALSE) + geom_boxplot(width = .2, alpha = .6, show.legend = FALSE) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;pointrange&quot;, show.legend = F, position = position_dodge(.175)) + scale_x_discrete(name = &quot;Condition&quot;, labels = c(&quot;Non-word&quot;, &quot;Word&quot;)) + scale_y_continuous(name = &quot;Reaction time (ms)&quot;, breaks = seq(200, 800, 100), limits = c(200, 800)) + scale_fill_viridis_d(option = &quot;E&quot;, name = &quot;Language group&quot;) + theme_minimal() Figure 6.1: Split-violin plot 6.2 Raincloud plots Raincloud plots combine a density plot, boxplot, raw data points, and any desired summary statistics for a complete visualisation of the data. They are so called because the density plot plus raw data is reminiscent of a rain cloud. rain_height &lt;- .1 ggplot(dat_long, aes(x = &quot;&quot;, y = rt, fill = language)) + # clouds introdataviz::geom_flat_violin(trim=FALSE, alpha = 0.4, position = position_nudge(x = rain_height+.05)) + # rain geom_point(aes(colour = language), size = 2, alpha = .5, show.legend = FALSE, position = position_jitter(width = rain_height, height = 0)) + # boxplots geom_boxplot(width = rain_height, alpha = 0.4, show.legend = FALSE, outlier.shape = NA, position = position_nudge(x = -rain_height*2)) + # mean and SE point in the cloud stat_summary(fun.data = mean_se, mapping = aes(color = language), show.legend = FALSE, position = position_nudge(x = rain_height * 3)) + # adjust layout scale_x_discrete(name = &quot;&quot;, expand = c(rain_height*3, 0, 0, 0.7)) + scale_y_continuous(name = &quot;Reaction time (ms)&quot;, breaks = seq(200, 800, 100), limits = c(200, 800)) + coord_flip() + facet_wrap(~factor(condition, levels = c(&quot;word&quot;, &quot;nonword&quot;), labels = c(&quot;Word&quot;, &quot;Non-Word&quot;)), nrow = 2) + # custom colours and theme scale_fill_viridis_d(option = &quot;E&quot;, name = &quot;Language group&quot;) + scale_colour_viridis_d(option =&quot;E&quot;) + theme_minimal() + theme(panel.grid.major.y = element_blank(), legend.position = c(0.8, 0.8), legend.background = element_rect(fill = &quot;white&quot;, color = &quot;white&quot;)) Figure 6.2: Raincloud plot 6.3 Ridge plots Ridge plots are a series of density plots and show the distribution of numeric values for several groups. Figure 6.3 shows data from (Nation 2017) and demonstrates how effective this type of visualisation can be to convey a lot of information very intuitively whilst being visually attractive. # read in data from Nation et al. 2017 data &lt;- read_csv(&quot;https://raw.githubusercontent.com/zonination/perceptions/master/probly.csv&quot;) # convert to long format and percents long &lt;- pivot_longer(data, cols = everything(), names_to = &quot;label&quot;, values_to = &quot;prob&quot;) %&gt;% mutate(label = factor(label, names(data), names(data)), prob = prob/100) # ridge plot ggplot(long, aes(x = prob, y = label, fill = label)) + ggridges::geom_density_ridges(scale = 2, show.legend = FALSE) + scale_x_continuous(name = &quot;Assigned Probability&quot;, limits = c(0, 1), labels = scales::percent) + # control space at top and bottom of plot scale_y_discrete(name = &quot;&quot;, expand = c(0.02, 0, .08, 0)) Figure 6.3: A ridge plot. 6.4 Alluvial plots Alluvial plots visualise multi-level categorical data through flows that can easily be traced in the diagram. library(ggalluvial) # simulate data for 4 years of grades from 500 students # with a correlation of 0.75 from year to year # and a slight increase each year dat &lt;- faux::sim_design( within = list(year = c(&quot;Y1&quot;, &quot;Y2&quot;, &quot;Y3&quot;, &quot;Y4&quot;)), n = 500, mu = c(Y1 = 0, Y2 = .2, Y3 = .4, Y4 = .6), r = 0.75, dv = &quot;grade&quot;, long = TRUE, plot = FALSE) %&gt;% # convert numeric grades to letters with a defined probability mutate(grade = faux::norm2likert(grade, prob = c(&quot;3rd&quot; = 5, &quot;2.2&quot; = 10, &quot;2.1&quot; = 40, &quot;1st&quot; = 20)), grade = factor(grade, c(&quot;1st&quot;, &quot;2.1&quot;, &quot;2.2&quot;, &quot;3rd&quot;))) %&gt;% # reformat data and count each combination tidyr::pivot_wider(names_from = year, values_from = grade) %&gt;% dplyr::count(Y1, Y2, Y3, Y4) # plot data with colours by Year1 grades ggplot(dat, aes(y = n, axis1 = Y1, axis2 = Y2, axis3 = Y3, axis4 = Y4)) + geom_alluvium(aes(fill = Y4), width = 1/6) + geom_stratum(fill = &quot;grey&quot;, width = 1/3, color = &quot;black&quot;) + geom_label(stat = &quot;stratum&quot;, aes(label = after_stat(stratum))) + scale_fill_viridis_d(name = &quot;Final Classification&quot;) + theme_minimal() + theme(legend.position = &quot;top&quot;) Figure 6.4: An alluvial plot showing the progression of student grades through the years. References "],["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion In this tutorial we aimed to provide a practical introduction to common data visualisation techniques using R. Whilst a number of the plots produced in this tutorial can be created in point-and-click software, the underlying skill-set developed by making these visualisations is as powerful as it is extendable. We hope that this tutorial serves as a jumping off point to encourage more researchers to adopt reproducible workflows and open-access software, in addition to beautiful data visualisations. "],["appendices.html", "Appendices", " Appendices The purpose of the main tutorial was to provide coverage of common data visualisations, in this section, we provide links to additional resources and well as extra code examples for customisation and types of plots that go beyond a standard beginners’ tutorial. "],["additional-resources.html", "Chapter 8 Additional resources", " Chapter 8 Additional resources There are a number of incredible open-access online resources that, using the skills you have developed in this tutorial, will allow you to start adapting your figures and plots to make them as informative as possible for your reader. Additionally, there are also many excellent resources that expand on some of the topics we have covered here briefly, particularly data wrangling, that can help you consolidate and expand your skill set. PsyTeachR The psyTeachR team at the University of Glasgow School of Psychology and Institute of Neuroscience and Psychology has successfully made the transition to teaching reproducible research using R across all undergraduate and postgraduate levels. Our curriculum now emphasizes essential ‘data science’ graduate skills that have been overlooked in traditional approaches to teaching, including programming skills, data visualisation, data wrangling and reproducible reports. Students learn about probability and inference through data simulation as well as by working with real datasets. These materials cover all the functions we have used in this tutorial in more depth and all have Creative Commons licences to allow their use and reuse without attribution. Level 1 Data Skills Level 2 Research Methods and Statistics Level 3 Statistical Models Msc Conversion Research Methods MSc Data Skills &amp; Simulation Installing R and RStudio Installing R - PsyTeachR Running R on your own computer (walkthrough videos) - Danielle Navarro R Markdown Introduction to R Markdown R Markdown: The Definitive Guide Data wrangling R for Data Science Text Mining with R Data visualisation R Graph Gallery Fundamentals of Data Vizualisation Data Vizualisation: A Practical Introduction "],["additional-advanced-plots-and-customisation-options.html", "Chapter 9 Additional advanced plots and customisation options 9.1 Adding lines to plots 9.2 Zooming in and out 9.3 Setting the axis values 9.4 Controlling the Legend 9.5 Setting A Lab Theme using theme() 9.6 Easter Egg - Overlaying Plots 9.7 Easter Egg - A Dumbbell Plot 9.8 Easter Egg - A Pie Chart", " Chapter 9 Additional advanced plots and customisation options 9.1 Adding lines to plots Vertical Lines - geom_vline() Often it can be useful to put a marker into our plots to highlight a certain criterion value. For example, if you were working with a scale that has a cut-off, perhaps the Austim Spectrum Quotient 10 (Allison, Auyeung, and Baron-Cohen 2012), then you might want to put a line at a score of 7; the point at which the researchers suggest the participant is referred further. Alternatively, thinking about the Stroop test we have looked at in this paper, perhaps you had a level of accuracy that you wanted to make sure was reached - let’s say 80%. If we refer back to Figure ??, which used the code below: ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) and displayed the spread of the accuracy scores as such: Figure 9.1: Histogram of accuracy scores. if we wanted to add a line at the 80% level then we could use the geom_vline() function, again from the ggplot2, with the argument of xintercept = 80, meaning cut the x-axis at 80, as follows: ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) + geom_vline(xintercept = 80) Figure 9.2: Histogram of accuracy scores with black solid vertical line indicating 80% accuracy. Now that looks ok but the line is a bit hard to see so we can change the style (linetype = value), color (color = \"color\") and weight (size = value) as follows: ggplot(dat_long, aes(x = acc)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Accuracy (0-100)&quot;) + geom_vline(xintercept = 80, linetype = 2, color = &quot;red&quot;, size = 1.5) Figure 9.3: Histogram of accuracy scores with red dashed vertical line indicating 80% accuracy. Horizontal Lines - geom_hline() Another situation may be that you want to put a horizontal line on your figure to mark a value of interest on the y-axis. Again thinking about our Stroop experiment, perhaps we wanted to indicate the 80% accuracy line on our boxplot figures. If we look at Figure 4.1, which used this code to display the basic boxplot: ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() Figure 9.4: Basic boxplot. we could then use the geom_hline() function, from the ggplot2, with, this time, the argument of yintercept = 80, meaning cut the y-axis at 80, as follows: ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() + geom_hline(yintercept = 80) Figure 9.5: Basic boxplot with black solid horizontal line indicating 80% accuracy. and again we can embellish the line using the same arguments as above. We will put in some different values here just to show the changes: ggplot(dat_long, aes(x = condition, y = acc)) + geom_boxplot() + geom_hline(yintercept = 80, linetype = 3, color = &quot;blue&quot;, size = 2) Figure 9.6: Basic boxplot with blue dotted horizontal line indicating 80% accuracy. LineTypes One thing worth noting is that the linetype argument can actually be specified as both a value or as a word. They match up as follows: Value Word linetype = 0 linetype = “blank” linetype = 1 linetype = “solid” linetype = 2 linetype = “dashed” linetype = 3 linetype = “dotted” linetype = 4 linetype = “dotdash” linetype = 5 linetype = “longdash” linetype = 6 linetype = “twodash” Diagonal Lines - geom_abline() The last type of line you might want to overlay on a figure is perhaps a diagonal line. For example, perhaps you have created a scatterplot and you want to have the true diagonal line for reference to the line of best fit. To show this, we will refer back to Figure 3.5 which displayed the line of best fit for the reaction time versus age, and used the following code: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Figure 9.7: Line of best fit for reaction time versus age. By eye that would appear to be a fairly flat relationship but we will add the true diagonal to help clarify. To do this we use the geom_abline(), again from ggplot2, and we give it the arguements of the slope (slope = value) and the intercept (intercept = value). We are also going to scale the data to turn it into z-scores to help us visualise the relationship better, as follows: dat_long_scale &lt;- dat_long %&gt;% mutate(rt_zscore = (rt - mean(rt))/sd(rt), age_zscore = (age - mean(age))/sd(age)) ggplot(dat_long_scale, aes(x = rt_zscore, y = age_zscore)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_abline(slope = 1, intercept = 0) Figure 9.8: Line of best fit (blue line) for reaction time versus age with true diagonal shown (black line). So now we can see the line of best fit (blue line) in relation to the true diagonal (black line). We will come back to why we z-scored the data in a minute, but first let’s finish tidying up this figure, using some of the customisation we have seen as it is a bit messy. Something like this might look cleaner: ggplot(dat_long_scale, aes(x = rt_zscore, y = age_zscore)) + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = .5) + geom_hline(yintercept = 0, linetype = &quot;solid&quot;, color = &quot;black&quot;, size = .5) + geom_vline(xintercept = 0, linetype = &quot;solid&quot;, color = &quot;black&quot;, size = .5) + geom_point() + geom_smooth(method = &quot;lm&quot;) Figure 9.9: Line of best fit (blue solid line) for reaction time versus age with true diagonal shown (black line dashed). That maybe looks a bit cluttered but it gives a nice example of how you can use the different geoms for adding lines to add information to your figure, clearly visualising the weak relationship between reaction time and age. Note: Do remember about the layering system however; you will notice that in the code for Figure 9.9 we have changed the order of the code lines so that the geom lines are behind the points! Top Tip: Your intercepts must be values you can see Thinking back to why we z-scored the data for that last figure, we sort of skipped over that, but it did serve a purpose. Here is the original data and the original scatterplot but with the geom_abline() added to the code: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_abline(slope = 1, intercept = 0) Figure 9.10: Line of best fit (blue solid line) for reaction time versus age with missing true diagonal. The code runs but the diagonal line is nowhere to be seen. The reason is that you figure is zoomed in on the data and the diagonal is “out of shot” if you like. If we were to zoom out on the data we would then see the diagonal line as such: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_abline(slope = 1, intercept = 0) + coord_cartesian(xlim = c(0,1000), ylim = c(0,60)) Figure 9.11: Zoomed out to show Line of best fit (blue solid line) for reaction time versus age with true diagonal (black line). So the key point is that your intercepts have to be set to visible for values for you to see them! If you run your code and the line does not appear, check that the value you have set can actually be seen on your figure. This applies to geom_abline(), geom_hline() and geom_vline(). 9.2 Zooming in and out Like in the example above, it can be very beneficial to be able to zoom in and out of figures, mainly to focus the frame on a given section. One function we can use to do this is the coord_cartesian(), in ggplot2. The main arguments are the limits on the x-axis (xlim = c(value, value)), the limits on the y-axis (ylim = c(value, value)), and whether to add a small expansion to those limits or not (expand = TRUE/FALSE). Looking at the scatterplot of age and reaction time again, we could use coord_cartesian() to zoom fully out: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + coord_cartesian(xlim = c(0,1000), ylim = c(0,100), expand = FALSE) Figure 9.12: Zoomed out on scatterplot with no expansion around set limits And we can add a small expansion by changing the expand argument to TRUE: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + coord_cartesian(xlim = c(0,1000), ylim = c(0,100), expand = TRUE) Figure 9.13: Zoomed out on scatterplot with small expansion around set limits Or we can zoom right in on a specific area of the plot if there was something we wanted to highlight. Here for example we are just showing the reaction times between 500 and 725 msecs, and all ages between 15 and 55: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + coord_cartesian(xlim = c(500,725), ylim = c(15,55), expand = TRUE) Figure 9.14: Zoomed in on scatterplot with small expansion around set limits And you can zoom in and zoom out just the x-axis or just the y-axis; just depends on what you want to show. 9.3 Setting the axis values Continuous scales You may have noticed that depending on the spread of your data, and how much of the figure you see, the values on the axes tend to change. Often we don’t want this and want the values to be constant. We have already used functions to control this in the main body of the paper - the scale_* functions. Here we will use scale_x_continuous() and scale_y_continuous() to set the values on the axes to what we want. The main arguments in both functions are the limits (limts = c(value, value)) and the breaks (the tick marks essentially, breaks = value:value). Note that the limits are just two values (minimum and maximum), whereas the breaks are a series of values (from 0 to 100, for example). If we use the scatterplot of age and reaction time, then our code might look like this: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,1000), breaks = 0:1000) + scale_y_continuous(limits = c(0,100), breaks = 0:100) Figure 9.15: Changing the values on the axes That actually looks rubbish because we simply have too many values on our axes, so we can use the seq() function, from baseR, to get a bit more control. The arguments here are the first value (from = value), the last value (last = value), and the size of the steps (by = value). For example, seq(0,10,2) would give all values between 0 and 10 in steps of 2, (i.e. 0, 2, 4, 6, 8 and 10). So using that idea we can change the y-axis in steps of 5 (years) and the x-axis in steps of 50 (msecs) as follows: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000,50)) + scale_y_continuous(limits = c(0,100), breaks = seq(0,100,5)) Figure 9.16: Changing the values on the axes using the seq() function Which gives us a much nicer and cleaner set of values on our axes. And if we combine that approach for setting the axes values with our zoom function (coord_cartesian()), then we can get something that looks like this: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(0,1000), breaks = seq(0,1000,50)) + scale_y_continuous(limits = c(0,100), breaks = seq(0,100,5)) + coord_cartesian(xlim = c(250,750), ylim = c(15,55)) Figure 9.17: Combining scale functions and zoom functions Which actually looks much like our original scatterplot but with better definition on the axes. So you can see we can actually have a lot of control over the axes and what we see. However, one thing to note, is that you should not use the limits argument within the scale_* functions as a zoom. It won’t work like that and instead will just disregard data. Look at this example: ggplot(dat_long, aes(x = rt, y = age)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + scale_x_continuous(limits = c(500,600)) ## Warning: Removed 166 rows containing non-finite values (stat_smooth). ## Warning: Removed 166 rows containing missing values (geom_point). Figure 9.18: Combining scale functions and zoom functions It may look like it has zoomed in on the data but actually it has removed all data outwith the limits. That is what the warnings are telling you, and you can see that as there is no data above and below the limits, but we know there should be based on the earlier plots. So scale_* functions can change the values on the axes, but coord_cartesian() is for zooming in and out. Discrete scales The same idea of limits within a scale_* function can also be used to change the order of categories on a discrete scale. For example if we look at our boxplots again in Figure 4.12, we see this figure: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 9.19: Using transparency on the fill color. The figures always default to the alphabetical order. Sometimes that is what we want; sometimes that is not what we want. If we wanted to switch the order of word and non-word so that the non-word condition comes first we would use the scale_x_discrete() function and set the limits within it (limits = c(\"category\",\"category\")) as follows: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + scale_x_discrete(limits = c(&quot;nonword&quot;,&quot;word&quot;)) + theme_minimal() Figure 9.20: Switching orders of categorical variables And that works just the same if you have more conditions, which you will see if you compare Figure 4.10 to the below figure where we have flipped the order of non-word and word from the original default alphabetical order ggplot(dat_long, aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) + scale_fill_viridis_d(option = &quot;E&quot;) + scale_x_discrete(limits = c(&quot;nonword&quot;,&quot;word&quot;)) + theme_minimal() Figure 9.21: Same as earlier figure but with order of conditions on x-axis altered. Changing Order of Factors Again, you have a lot of control beyond the default alphabetical order that ggplot2 tends to plot in. One question you might have though is why monolingual and bilingual are not in alphabetical order? f they were then the bilingual condition would be plotted first. The answer is, thinking back to the start of the paper, we changed our conditions from 1 and 2 to the factor names of monolingual and bilingual, and ggplot maintains that factor order when plotting. So if we want to plot it in a different fashion we need to do a bit of factor reordering. This can be done much like earlier using the factor() function and stating the order of conditions we want (levels = c(\"factor\",\"factor\")). But be careful with spelling as it must match up to the names of the factors that already exist. In this example, we will reorder the factors so that bilingual is presented first but leave the order of word and non-word as the alphabetical default. Note in the code though that we are not permanently storing the factor change as we don’t want to keep this new order. We are just changing the order “on the fly” for this one example before putting it into the plot. dat_long %&gt;% mutate(language = factor(language, levels = c(&quot;bilingual&quot;,&quot;monolingual&quot;))) %&gt;% ggplot(aes(x = condition, y= rt, fill = language)) + geom_violin() + geom_boxplot(width = .2, fatten = NULL, position = position_dodge(.9)) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, position = position_dodge(.9)) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1, position = position_dodge(.9)) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 9.22: Same as earlier figure but with order of conditions on x-axis altered. And if we compare this new figure to the original, side-by-side, we see the difference: Figure 9.23: Switching factor orders 9.4 Controlling the Legend Using the guides() Whilst we are on the subject of changing order and position of elements of the figure, you might think about changing the position of a figure legend. There is actually a few ways of doing it but a simple approach is to use the the guides() function and add that to the ggplot chain. For example, if we run the below code and look at the output: ggplot(dat_long, aes(x = condition, y= rt, fill = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + guides(fill = &quot;none&quot;) + theme_minimal() Figure 9.24: Figure Legend removed using guides() We see the same display as Figure 9.19 but with no legend. That is quite useful because the legend just repeats the x-axis and becomes redundant. The guides() function works but setting the legened associated with the fill layer (i.e. fill = condition) to \"none\", basically removing it. One thing to note with this approach is that you need to set a guide for every legend, otherwise a legend will appear. What that means is that if you had set both fill = condition and color = condition, then you would need to set both fill and color to \"none\" within guides() as follows: ggplot(dat_long, aes(x = condition, y= rt, fill = condition, color = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + guides(fill = &quot;none&quot;, color = &quot;none&quot;) + theme_minimal() Figure 9.25: Removing more than one legend with guides() Whereas if you hadn’t used guides() you would see the following: ggplot(dat_long, aes(x = condition, y= rt, fill = condition, color = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() Figure 9.26: Figure with more than one Legend The key thing to note here is that in the above figure there is actually two legends (one for fill and one for color) but they are overlaid on top of each other as they are associated with the same variable. You can test this by removing either one of the options from the guides() function. One of the legends will still remain. So you need to turn them both off or you can use it to leave certain parts clear. Using the theme() An alternative to the guides function is using the theme() function. The theme() function can actually be used to control a whole host of options in the plot, which we will come on to, but you can use it as a quick way to turn off the legend as follows: ggplot(dat_long, aes(x = condition, y= rt, fill = condition, color = condition)) + geom_violin(alpha = .4) + geom_boxplot(width = .2, fatten = NULL, alpha = .5) + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.data = &quot;mean_se&quot;, geom = &quot;errorbar&quot;, width = .1) + scale_fill_viridis_d(option = &quot;E&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) Figure 9.27: Removing the legend with theme() What you can see is that within the theme() function we set an argument for legend.position and we set that to \"none\" - again removing the legend entirely. One difference to note here is that it removes all aspects of the legend where as, as we said, using guides() allows you to control different parts of the legend (either leaving the fill or color showing or both). So using the legend.position = \"none\" is a bit more brute force and can be handy when you are using various different means of distinguishing between conditions of a variable and don’t want to have to remove each aspect using the guides(). An extension here of course is not just removing the legend, but moving the legend to a different position. This can be done by setting legend.position = ... to either \"top\", \"bottom\", \"left\" or \"right\" as shown: Figure 9.28: Legend position options using theme() Or even as a coordinate within your figure expressed as a propotion of your figure - i.e. c(x = 0, y = 0) would be the bottom left of your figure and c(x = 1, y = 1) would be the top right, as shown here: Figure 9.29: Legend position options using theme() And so with a little trial and error you can position your legend where you want it without crashing into your figure, hopefully! 9.5 Setting A Lab Theme using theme() The theme() function, as we mentioned, does a lot more than just change the position of a legend and can be used to really control a variety of elements and to eventually create your own “theme” for your figures - say you want to have a consistent look to your figures across your publications or across your lab posters. We will try to show some of that here, but first lets start with a very basic plot that we have seen before: THIS BIT NEEDS WORK # set up custom theme to add to all plots mytheme &lt;- theme_minimal( # always start with a base theme_**** base_size = 16, # 16-point font (adjusted for axes) base_family = &quot;Helvetica&quot; # font style ) + # add more specific customisations with theme() theme( text = element_text(color = &quot;white&quot;), # most text axis.text = element_text(color = &quot;grey60&quot;), # axis label text axis.line = element_line(color = &quot;grey60&quot;), # x and y axes plot.background = element_rect(fill = &quot;black&quot;), # main background panel.background = element_blank(), # defaults to plot background fill panel.grid = element_blank() # get rid of gridlines ) # plot with custom theme ggplot(diamonds, aes(carat, price, color = cut)) + geom_smooth() + mytheme Figure 9.30: buidling something like this idea 9.6 Easter Egg - Overlaying Plots Hopefully from some of the materials we have shown you, you will have found ways of presenting data in an informative manner - for example, we have shown violin plots and how they can be effective, when combined with boxplots, at displaying distributions. However, if you are familiar with other software you may be used to seeing this sort of information displayed differently, as perhaps a histogram with a normal curve overlaid. Whist the violin plots are better to convey that information we thought it might help to see alternative approaches here. Really it is about overlaying some of the plots we have already shown, but with some slight adjustments. FOr example, lets look at the histogram and density plot of reaction times we saw earlier - shown here side by side for convenience. a &lt;- ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + labs(subtitle = &quot;+ geom_histogram()&quot;) b &lt;- ggplot(dat_long, aes(x = rt)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) + labs(subtitle = &quot;+ geom_density()&quot;) a+b Figure 9.31: TRUE Now that in itself is fairly informative but perhaps takes up a lot of room so one option using some of the features of the patchwork library would be to inset the density plot in the top right of the histogram. We already showed a little of patchwork earlier so we won’t repeat it here but all we are doing is placing one of the figures (the density plot) within the inset_element() function and applying some appropriate values to position the inset - through a little trial and error - based on the bottom left corner of the plot area being left = 0, bottom = 0, and the top right corner being right = 1, top = 1: a &lt;- ggplot(dat_long, aes(x = rt)) + geom_histogram(binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + scale_x_continuous(name = &quot;Reaction time (ms)&quot;) b &lt;- ggplot(dat_long, aes(x = rt)) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) a + inset_element(b, left = 0.6, bottom = 0.6, right = 1, top = 1) Figure 9.32: Insetting a plot within a plot using inset_element() from the patchwork library But of course that only works if there is space for the inset and it doesn’t start overlapping on the main figure. This next approach fully overlays the density plot on top of the histogram. There is one main change though and that is the addition of aes(y=..density..) within geom_histogram(). This tells the histogram to now be plotted in terms of density and not count, meaning that the density plot and the histogram and now based on the same y-axis: ggplot(dat_long, aes(x = rt)) + geom_histogram(aes(y = ..density..), binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + geom_density()+ scale_x_continuous(name = &quot;Reaction time (ms)&quot;) Figure 9.33: A histogram with density plot overlaid The main thing to not in the above figure is that both the histogram and the density plot are based on the data you have collected. An alternative that you might want to look at it is plotting a normal distribution on top of the histogram based on the mean and standard deviation of the data. This is a bit more complicated but works as follows: ggplot(dat_long, aes(rt)) + geom_histogram(aes(y = ..density..), binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + stat_function( fun = dnorm, args = list(mean = mean(dat_long$rt), sd = sd(dat_long$rt)) ) Figure 9.34: A histogram with normal distribution based on the data overlaid The first part of this approach is identical to what we say above but instead of using geom_density() we are using a statistics function called stat_function() similar to ones we saw earlier when plotting means and standard deviations. What stat_function() is doing is taking the Normal distribution density function, fun = dnorm (read as function equals density normal), and then the mean of the data (mean = mean(dat_long$rt)) and the standard deviation of the data sd = sd(dat_long$rt) and creates a distribution based on those values. The args refers to the arguments that the dnorm function takes, and they are passed to the function as a list (list()). But from there, you can then start to alter the linetype, color, and thickness (lwd = 3 for example) as you please. ggplot(dat_long, aes(rt)) + geom_histogram(aes(y = ..density..), binwidth = 10, fill = &quot;white&quot;, color = &quot;black&quot;) + stat_function( fun = dnorm, args = list(mean = mean(dat_long$rt), sd = sd(dat_long$rt)), color = &quot;red&quot;, lwd = 3, linetype = 2 ) Figure 9.35: Changing the line of the stat_function() 9.7 Easter Egg - A Dumbbell Plot A nice way of representing a change across different conditions, within participants or across timepoints, is the dumbbell chart. These figures can do a lot of heavy lifting in conveying patterns within the data and are not as hard to create in ggplot as they might first appear. The premise is that you need the start point, in terms of x (x =) and y (y =), and the end point, again in terms of x (xend =) and y (yend =). You draw a line between those two points using geom_segment() and then add a data point at the both ends of the line using geom_point(). So for example, we will use the average accuracy scores for the word and non-word conditions, for monolingual and bilinguals, to demonstrate. We could do the same figure for all participants but as we have 100 participants it can be a bit wild. We first need to create the averages using a little bit of data wrangling we have seen: dat_avg &lt;- dat %&gt;% group_by(language) %&gt;% summarise(mean_acc_nonword = mean(acc_nonword), mean_acc_word = mean(acc_word)) So our data looks as follows: language mean_acc_nonword mean_acc_word monolingual 84.87273 94.87273 bilingual 84.93333 95.17778 With our average accuracies for non-word trials in ** nom mean_acc_nonword ** and our average accuracies for word trials in ** nom mean_acc_word **. And now we can create our dumbbell plot as follows: ggplot(dat_avg) + geom_segment(aes(x = mean_acc_nonword, y = language, xend = mean_acc_word, yend = language)) + geom_point(aes(x = mean_acc_nonword, y = language), color = &quot;red&quot;) + geom_point(aes(x = mean_acc_word, y = language), color = &quot;blue&quot;) + labs(x = &quot;Change in Accuracy&quot;) Figure 9.36: A dumbbell plot of change in Average Accuracy from Non-word trials (red dots) to Word trials (blue dots) for monolingual and bilingual participants. Which actually gives the least exciting figure ever as both groups showed the same change from the non-word trials (red dots) to the word trials (blue dots) but we can break the code down a bit just to highlight what we are doing, remembering the idea about layers. Layers one and two add the basic background and black line from the start point (x,y), the mean accuracy of non-word trials for the two conditions, to the end point (xend, yend), the mean accuracy of word trials for the two conditions: Figure 9.37: Building the bars of our dumbbells. The (x,y) and (xend, yend) have been added to show the values you need to consider and enter to create the dumbbell and the remaining lines add the dots at the end of the dumbells and changes the x axis label to something useful: Figure 9.38: Adding the weights to the dumbbells. Red dots are added in one layer to show Average Accuracy of Non-word trials, and blue dots are added in final layer to show Average Accuracy of Word trials. Of course, worth remembering, it is better to always think of the dumbbell as a start and end point, not left and right, as had accuracy gone down when moving from Non-word trials to Word trials then our bars would run the opposite direction. If you repeat the above process using reaction times instead of accuracy you will see what we mean. 9.8 Easter Egg - A Pie Chart Pie Charts are not the best form of visualisation as they generally require people to compare areas and/or angles which is a fairly unintuitive means of doing a comparison. The are so disliked in many fields that ggplot does not actually have a geom_...() function to create one. But, there is always somebody that wants to create a pie chart regardless and who are we to judge. So here would be the code to produce a pie chart of the demographic data we saw in the start of the paper: count_dat &lt;- dat %&gt;% group_by(language) %&gt;% count() %&gt;% ungroup() %&gt;% mutate(percent = (n/sum(n)*100)) ggplot(count_dat, aes(x = &quot;&quot;, y = percent, fill = language)) + geom_bar(width = 1, stat=&quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + theme( axis.title = element_blank(), panel.grid = element_blank(), panel.border = element_blank(), axis.ticks = element_blank(), axis.text.x = element_blank() ) + geom_text(aes(y = c(75, 25), label = paste(percent, &quot;%&quot;)), size = 6) Figure 9.39: A pie chart of the demographics Note that this is effectively creating a stacked bar chart with no x variable (i.e. x = \"\") and then wrapping the y-axis into a circle (i.e. coord_polar(\"y\", start = 0)). That is what the first three lines of the ggplot code does: Figure 9.40: The basis of a pie chart The remainder of the code is used to remove the various panel and tick lines, and text, setting them all to element_blank() through the theme() functions we saw above, and to add new labelling text on top of the pie chart at specific y-values (i.e. y = c(75,25)). But remember, friends don’t let friends make pie charts! "]]
